# Ollama AI Chat

This is a simple command-line chat application that connects to an Ollama server running locally. It uses the Llama 2 model to generate AI responses.

## Features
V1
- Interactive chat with an AI assistant
- Maintains conversation context
- Easy to use from the terminal

V2
-Allows the LLM to use tts to speak out its responses
-Allows the user to use voice inputs to talk to the ai via stt

## Requirements
- Python 3.x
- [requests](https://pypi.org/project/requests/) library
- Ollama server running locally (default: http://localhost:11434)

## Setup
1. **Install Python 3** if you haven't already.
2. **Install the required Python package:**
   ```powershell
   pip install requests
   ```
3. **Start the Ollama server:**
   ```powershell
   ollama serve
   ```
   (Make sure the Llama 2 model is available. You can pull it with `ollama pull llama2`.)
4. **Run the chat application:**
   ```powershell
   python aiChat.py
   ```

## Usage
- Type your message and press Enter to chat with the AI.
- Type `exit` to quit the application.

## File Overview
- `aiChat.py`: Main Python script for the chat application.
- `README`: This file.

## Example
```
Welcome to the AI Chat! Type 'exit' to quit.

You: Hello!
AI: Hello! How can I assist you today?
You: exit
Goodbye! linga guli guli wacha linga gu linga gu
```

---

Created June 2025.
